{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "* **After applying initial EDA to our datasets, We'll now target the following preprocessing tasks:**\n",
    "\n",
    "    * Handle null values and inconsistencies for all features.\n",
    "    * Create a target variable (issue_happened) reflecting whether\n",
    "    a problem happened during the transfer of this package/receptacle.\n",
    "    * Propose, validate assumptions (with Ms.Lasmi), and work based on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_df = pd.read_csv('../data/raw/packages_data_2023_2025.csv', encoding='latin-1', delimiter=';')\n",
    "receptacles_df = pd.read_csv('../data/raw/receptacle_data_2023_2025.csv', encoding='latin-1', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "* Columns Renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_df = packages_df.rename(columns={'établissement_postal': 'etablissement_postal', 'next_établissement_postal': 'next_etablissement_postal'})\n",
    "receptacles_df = receptacles_df.rename(columns={'ï»¿RECPTCL_FID': 'RECPTCL_FID', 'EVENT_TYPECD': 'EVENT_TYPE_CD', 'nextetablissement_postal': 'next_etablissement_postal'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "* `date` type adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_df['date'] = pd.to_datetime(packages_df['date'])\n",
    "receptacles_df['date'] = pd.to_datetime(receptacles_df['date'])\n",
    "packages_df['RECPTCL_FID'] = packages_df['RECPTCL_FID'].str.strip()\n",
    "packages_df['MAILITM_FID'] = packages_df['MAILITM_FID'].str.strip()\n",
    "packages_df['etablissement_postal'] = packages_df['etablissement_postal'].str.strip()\n",
    "packages_df['next_etablissement_postal'] = packages_df['next_etablissement_postal'].str.strip()\n",
    "receptacles_df['etablissement_postal'] = receptacles_df['etablissement_postal'].str.strip()\n",
    "receptacles_df['next_etablissement_postal'] = receptacles_df['next_etablissement_postal'].str.strip()\n",
    "receptacles_df['RECPTCL_FID'] = receptacles_df['RECPTCL_FID'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "receptacles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "receptacles_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_df['etablissement_postal'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "* `etablissement_postal` have 26772 null values (2.7% of the whole dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "* As its null values are less than 5% of the dataset (2.7%), we drop these null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_df = packages_df[~packages_df['etablissement_postal'].isna()]\n",
    "packages_df['etablissement_postal'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "* We propose to consider the packages having null `next_etablissement_postal`\n",
    "as having issue during transfer, we'll try to validate that using\n",
    "`EVENT_TYPE_CD` also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages_df['next_etablissement_postal'] = packages_df['next_etablissement_postal'].fillna('Unknown')\n",
    "# packages_df['next_etablissement_postal'].isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "* Let's check if `EVENT_TYPE_CD` can indicate whether the `next_etablissement_postal` is null or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_unknown_next_etablissement = packages_df[packages_df['next_etablissement_postal'].isna()]\n",
    "# keep only top EVENT_TYPES_ID\n",
    "packages_unknown_next_etablissement = packages_unknown_next_etablissement['EVENT_TYPE_CD'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "packages_unknown_next_etablissement.head(10).plot(kind='bar')\n",
    "plt.xlabel('EVENT TYPE CD')\n",
    "plt.ylabel('Null Next Etablissement Postal')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "* `EVENT_TYPE_CD` doesn't indicate null values of `next_etablissement_postal`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "* the following code cell fills the `next_etablissement_postal` using the next `etablissement_postal` for the same package.\n",
    "* if the last route for a specific package is null, then it keeps it null because there's no next `etablissement_postal` for that package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ensure the dataframe is sorted (same as before)\n",
    "packages_df = packages_df.sort_values(['MAILITM_FID', 'date'])\n",
    "\n",
    "# 2. Look ahead to the next row's postal code and ID\n",
    "shifted_postal = packages_df['etablissement_postal'].shift(-1)\n",
    "shifted_id = packages_df['MAILITM_FID'].shift(-1)\n",
    "\n",
    "# 3. Identify the \"boundaries\" where the postal code changes within the same package\n",
    "# This marks the last row of a block with the value of the start of the next block\n",
    "is_boundary = (packages_df['etablissement_postal'] != shifted_postal) & \\\n",
    "              (packages_df['MAILITM_FID'] == shifted_id)\n",
    "\n",
    "# 4. Use grouped backfill to broadcast those values to all preceding rows in the block\n",
    "# This replaces your 'blocks.map' logic with a single vectorized pass\n",
    "fill_values = shifted_postal.where(is_boundary).groupby(packages_df['MAILITM_FID']).bfill()\n",
    "\n",
    "# 5. Fill only the NaNs in the existing column to match your original logic\n",
    "packages_df['next_etablissement_postal'] = packages_df['next_etablissement_postal'].fillna(fill_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_df_copy = packages_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_df_copy['MAILITM_FID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "* Like this, we've mostly handled all null values and inconsitencies for `packages` dataset, and we can start applying tasks further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "* **We'll be doing the same steps for `receptacle` dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "receptacles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "receptacles_df = receptacles_df[~receptacles_df['etablissement_postal'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "* apply the function that fills null values of `next_etablissement_postal` using `etablissement_postal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ensure sorted order\n",
    "receptacles_df = receptacles_df.sort_values(['RECPTCL_FID', 'date'])\n",
    "\n",
    "# 2. Identify transitions where the postal code changes within the same receptacle\n",
    "# This finds the \"start of the next block\"\n",
    "next_postal = receptacles_df['etablissement_postal'].shift(-1)\n",
    "next_id = receptacles_df['RECPTCL_FID'].shift(-1)\n",
    "\n",
    "# Logic: If current postal != next postal AND we are still in the same ID, \n",
    "# then 'next_postal' is the value of the next block.\n",
    "is_boundary = (receptacles_df['etablissement_postal'] != next_postal) & \\\n",
    "              (receptacles_df['RECPTCL_FID'] == next_id)\n",
    "\n",
    "# 3. Create a series that only contains values at those boundaries\n",
    "boundary_values = next_postal.where(is_boundary)\n",
    "\n",
    "# 4. Use grouped backfill (bfill) to propagate the next block's source \n",
    "# to all rows in the current block\n",
    "filled_values = boundary_values.groupby(receptacles_df['RECPTCL_FID']).bfill()\n",
    "\n",
    "# 5. Fill NaNs in the target column as per your original logic\n",
    "receptacles_df['next_etablissement_postal'] = receptacles_df['next_etablissement_postal'].fillna(filled_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "receptacles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "receptacles_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "receptacles_df_copy = receptacles_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "* Null values are mostly gone, but there are still some illogical packages' and receptacles' routes between `etablissement`\n",
    "* We'll treat these logical routes now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each package (group of rows), check whether there's any illogical route\n",
    "# between 'etablissement_postal' and 'next_etablissement_postal'\n",
    "def isPackageIllogical(group):\n",
    "    return (\n",
    "        group['next_etablissement_postal']\n",
    "        .iloc[:-1]\n",
    "        .ne(group['etablissement_postal'].shift(-1).iloc[:-1])\n",
    "        .any()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "illogical_packages = packages_df_copy.groupby('MAILITM_FID').apply(isPackageIllogical)\n",
    "illogical_packages.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "105262 / packages_df_copy['MAILITM_FID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "* 103376 Packages have illogical routes (98%) of all packages\n",
    "* as a lot of packages have at least one illogical route, we'll create two datasets and keep the one that gives the best values\n",
    "* 1st dataset `clean` -> drop all packages having at leeast one illogical route\n",
    "* 2nd dataset `chaotic` -> the current dataset.\n",
    "* For the last two datasets, we add a feature `illogical` to flag illogical routes, it may be useful later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_packages_df = packages_df_copy[~packages_df_copy['MAILITM_FID'].isin(illogical_packages[illogical_packages].index)]\n",
    "clean_packages_df['MAILITM_FID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_packages_df['MAILITM_FID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "* Defining a new dataframe `illogical_counts` which shows each package and the number of illogical routes it has\n",
    "* An illogical route is a violation in the logical order of the package between (les etablissements)\n",
    "* Example of an illogical route:\n",
    "a package going from `ETAB_0001` -> `ETAB_0092`\n",
    "in the next row of the same package we find it going from a different etablissement than the one it went to previously, like `ETAB_0019` -> `ETAB_0102` where it should be `ETAB_0092` -> `ETAB_0102`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Standardize IDs in the source dataframe first\n",
    "packages_df_copy['MAILITM_FID'] = packages_df_copy['MAILITM_FID'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# 2. Vectorized calculation (Logic equivalent to your iloc[:-1] comparison)\n",
    "# We look at the next row's postal code and check if the package ID is the same\n",
    "shifted_postal = packages_df_copy['etablissement_postal'].shift(-1)\n",
    "is_same_package = packages_df_copy['MAILITM_FID'] == packages_df_copy['MAILITM_FID'].shift(-1)\n",
    "\n",
    "# A mismatch counts if the next row is the same package but has a different postal code\n",
    "mismatches = (packages_df_copy['next_etablissement_postal'] != shifted_postal) & is_same_package\n",
    "\n",
    "# 3. Sum the mismatches per group (this produces a unique ID list)\n",
    "illogical_counts = (\n",
    "    mismatches.groupby(packages_df_copy['MAILITM_FID'], sort=False)\n",
    "    .sum()\n",
    "    .astype(int)\n",
    "    .reset_index(name='n_illogical_routes')\n",
    ")\n",
    "\n",
    "illogical_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "illogical_counts['MAILITM_FID'] = illogical_counts['MAILITM_FID'].str.strip().str.upper()\n",
    "illogical_counts[illogical_counts['n_illogical_routes'] > 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "illogical_counts[illogical_counts['n_illogical_routes'] <= 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "illogical_counts[illogical_counts['MAILITM_FID'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_illogical_routes_packages = illogical_counts[illogical_counts['n_illogical_routes'] > 0]['MAILITM_FID'].unique()\n",
    "len(multiple_illogical_routes_packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify sums\n",
    "print(f\"Total packages: {packages_df_copy['MAILITM_FID'].nunique()}\")\n",
    "print(f\"Clean (0 illogical): {clean_packages_df['MAILITM_FID'].nunique()}\")\n",
    "print(f\"More than 0 illogical: {len(multiple_illogical_routes_packages)}\")\n",
    "print(f\"Should equal total: {packages_df_copy['MAILITM_FID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "* Storing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_packages_df.to_csv('../data/interim/clean_packages_df.csv')\n",
    "packages_df_copy.to_csv('../data/interim/chaotic_packages_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "### Handling Illogical Routes for receptacles (same logic with packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "receptacles_df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each receptacle (group of rows), check whether there's any illogical route\n",
    "# between 'etablissement_postal' and 'next_etablissement_postal'\n",
    "def isReceptacleIllogical(group):\n",
    "    return (\n",
    "        group['next_etablissement_postal']\n",
    "        .iloc[:-1]\n",
    "        .ne(group['etablissement_postal'].shift(-1).iloc[:-1])\n",
    "        .any()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "illogical_receptacles = receptacles_df_copy.groupby('RECPTCL_FID').apply(isReceptacleIllogical)\n",
    "illogical_receptacles.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of illogical receptacles on the total number of receptacles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_receptacles_df = receptacles_df_copy[~receptacles_df_copy['RECPTCL_FID'].isin(illogical_receptacles[illogical_receptacles].index)]\n",
    "clean_receptacles_df['RECPTCL_FID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Standardize IDs in the source dataframe first\n",
    "receptacles_df_copy['RECPTCL_FID'] = receptacles_df_copy['RECPTCL_FID'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# 2. Vectorized calculation (Logic equivalent to your iloc[:-1] comparison)\n",
    "# We look at the next row's postal code and check if the receptacle ID is the same\n",
    "shifted_postal = receptacles_df_copy['etablissement_postal'].shift(-1)\n",
    "is_same_receptacle = receptacles_df_copy['RECPTCL_FID'] == receptacles_df_copy['RECPTCL_FID'].shift(-1)\n",
    "\n",
    "# A mismatch counts if the next row is the same package but has a different postal code\n",
    "mismatches = (receptacles_df_copy['next_etablissement_postal'] != shifted_postal) & is_same_receptacle\n",
    "\n",
    "# 3. Sum the mismatches per group (this produces a unique ID list)\n",
    "rcp_illogical_counts = (\n",
    "    mismatches.groupby(receptacles_df_copy['RECPTCL_FID'], sort=False)\n",
    "    .sum()\n",
    "    .astype(int)\n",
    "    .reset_index(name='n_illogical_routes')\n",
    ")\n",
    "\n",
    "rcp_illogical_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_illogical_routes_receptacles = rcp_illogical_counts[rcp_illogical_counts['n_illogical_routes'] > 0]['RECPTCL_FID'].unique()\n",
    "len(multiple_illogical_routes_receptacles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify sums\n",
    "print(f\"Total receptacles: {receptacles_df_copy['RECPTCL_FID'].nunique()}\")\n",
    "print(f\"Clean (0 illogical): {clean_receptacles_df['RECPTCL_FID'].nunique()}\")\n",
    "print(f\"More than 0 illogical: {len(multiple_illogical_routes_receptacles)}\")\n",
    "print(f\"Should equal total: {receptacles_df_copy['RECPTCL_FID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_receptacles_df.to_csv('../data/interim/clean_receptacles_df.csv')\n",
    "receptacles_df_copy.to_csv('../data/interim/chaotic_receptacles_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
