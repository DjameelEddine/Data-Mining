{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "make sure to rename the columns by removing é\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) for Packages and Receptacle Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "packages_df = pd.read_csv('../data/raw/packages_data_2023_2025.csv',delimiter=';')\n",
    "receptacle_df = pd.read_csv('../data/raw/receptacle_data_2023_2025.csv',delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename for consistency\n",
    "receptacle_df.rename(columns={\n",
    "    'EVENT_TYPECD': 'EVENT_TYPE_CD',\n",
    "    'nextetablissement_postal': 'next_etablissement_postal'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_df.shape, receptacle_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dates to dateTime for compatibility\n",
    "packages_df['date'] = pd.to_datetime(packages_df['date'])\n",
    "receptacle_df['date'] = pd.to_datetime(receptacle_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "receptacle_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "receptacle_df.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    " Initial Observations\n",
    "- both datasets cover the period from 2023 to 2025\n",
    "- we have no target variable in either dataset\n",
    "- for packages dataset:\n",
    "    - 6 features in total with 5 categorical and 1 numerical\n",
    "    - MAILITM_FID is unique identifier for each package\n",
    "    - RECPTCL_FID is foreign key linking to receptacle dataset\n",
    "    - etablissement_postal and next_etablissement_postal have some null values\n",
    "- for receptacle dataset:\n",
    "    - 5 features in total with 4 categorical and 1 numerical\n",
    "    - RECPTCL_FID is unique identifier for each receptacle\n",
    "    - EVENT_TYPE_CD has some null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in packages_df.columns:\n",
    "    print(f'{column} has {packages_df[column].nunique()} unique values.')\n",
    "    print(f'{column} has {packages_df[column].isnull().sum()} null values.')\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in receptacle_df.columns:\n",
    "    print(f'{column} has {receptacle_df[column].nunique()} unique values.')\n",
    "    print(f'{column} has {receptacle_df[column].isnull().sum()} null values.')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "we notice the following:<br>\n",
    "- receptacle dataset has more unique values for RECPTCL_FID than packages dataset, indicating one-to-many relationship<br>\n",
    "- MAILITM_FID is unique in packages dataset.<br>\n",
    "- packages dataset have more unique date values than receptacle dataset.<br>\n",
    "- both datasets have null values in etablissement_postal and next_etablissement_postal columns. This requires processing later on<br>\n",
    "- packages dataset has more unique values in the next_etablissement_postal column compared to receptacle dataset but also more null values. **further investigation is needed to understand why**<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "receptacle_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "for EVENT_TYPE_CD we notice different range of values for packages and receptacle datasets indicating different types of events.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "#### Visualizations\n",
    "for now we will visualize the distribution of EVENT_TYPE_CD in both datasets.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of EVENT_TYPE_CD in packages dataset\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=packages_df,x='EVENT_TYPE_CD')\n",
    "plt.title('distribution of EVENT_TYPE_CD in packages dataset')\n",
    "plt.xlabel('EVENT_TYPE_CD')\n",
    "plt.ylabel('count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of EVENT_TYPE_CD in receptacle dataset\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=receptacle_df,x='EVENT_TYPE_CD')\n",
    "plt.title('distribution of EVENT_TYPE_CD in Receptacle dataset')\n",
    "plt.xlabel('EVENT_TYPE_CD')\n",
    "plt.ylabel('count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "for etablissement_postal and next_etablissement_postal I will start with visualizing the receptacle dataset since the packages dataset has a lot of unique values<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of etablissement_postal in receptacle dataset\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=receptacle_df,x='etablissement_postal')\n",
    "plt.title('distribution of etablissement_postal in Receptacle dataset')\n",
    "plt.xlabel('etablissement_postal')\n",
    "plt.ylabel('count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of next_etablissement_postal in receptacle dataset\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=receptacle_df,x='next_etablissement_postal')\n",
    "plt.title('distribution of next_etablissement_postal in Receptacle dataset')\n",
    "plt.xlabel('next_etablissement_postal')\n",
    "plt.ylabel('count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.  Top 10 locations to keep the map small\n",
    "top_locs = receptacle_df['etablissement_postal'].value_counts().head(10).index\n",
    "top_next = receptacle_df['next_etablissement_postal'].value_counts().head(10).index\n",
    "\n",
    "# 2. include only these top locations\n",
    "filtered_df = receptacle_df[\n",
    "    (receptacle_df['etablissement_postal'].isin(top_locs)) &\n",
    "    (receptacle_df['next_etablissement_postal'].isin(top_next))\n",
    "]\n",
    "\n",
    "# 3. Create a Matrix (Cross-tabulation)\n",
    "matrix = pd.crosstab(filtered_df['etablissement_postal'], filtered_df['next_etablissement_postal'])\n",
    "\n",
    "# 4. Plot Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(matrix, cmap='Reds', annot=True, fmt='d', linewidths=.5)\n",
    "plt.title(\"Most Frequent Routes (Origin vs Destination) - Receptacle Dataset\")\n",
    "plt.xlabel(\"Next Destination\")\n",
    "plt.ylabel(\"Current Location\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "we notice that some etablissements have significantly higher traffic compared to others, indicating  major distribution centers.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "for etablissement_postal and next_etablissement_postal we will create a heatmap to visualize the flow between current location and next destination.<br>\n",
    "Count of parcels moving from A to B to see the density of connections between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.  Top 10 locations to keep the map small\n",
    "top_locs = packages_df['etablissement_postal'].value_counts().head(10).index\n",
    "top_next = packages_df['next_etablissement_postal'].value_counts().head(10).index\n",
    "\n",
    "# 2. include only these top locations\n",
    "filtered_df = packages_df[\n",
    "    (packages_df['etablissement_postal'].isin(top_locs)) &\n",
    "    (packages_df['next_etablissement_postal'].isin(top_next))\n",
    "]\n",
    "\n",
    "# 3. Create a Matrix (Cross-tabulation)\n",
    "matrix = pd.crosstab(filtered_df['etablissement_postal'], filtered_df['next_etablissement_postal'])\n",
    "\n",
    "# 4. Plot Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(matrix, cmap='Reds', annot=True, fmt='d', linewidths=.5)\n",
    "plt.title(\"Most Frequent Routes (Origin vs Destination) - Packages Dataset\")\n",
    "plt.xlabel(\"Next Destination\")\n",
    "plt.ylabel(\"Current Location\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count packages per location\n",
    "location_counts = packages_df['etablissement_postal'].value_counts().reset_index()\n",
    "location_counts.columns = ['Location', 'Volume']\n",
    "\n",
    "# keep only top 20 busiest centers\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Volume', y='Location', data=location_counts.head(20), palette='viridis')\n",
    "plt.title(\"Top 20 Busiest Postal Centers\")\n",
    "plt.xlabel(\"Number of Packages\")\n",
    "plt.ylabel(\"Center ID\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "we notice the same pattern as before with some etablissements having significantly higher traffic compared to others.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Extract Time Features\n",
    "packages_df['hour'] = packages_df['date'].dt.hour\n",
    "packages_df['day_of_week'] = packages_df['date'].dt.day_name()\n",
    "\n",
    "# 2. Create a Pivot Table (Cross-tabulation)\n",
    "# Rows = Day, Cols = Hour, Values = Count of Scans\n",
    "heatmap_data = pd.crosstab(\n",
    "    packages_df['day_of_week'],\n",
    "    packages_df['hour']\n",
    ")\n",
    "\n",
    "days_order = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "heatmap_data = heatmap_data.reindex(days_order)\n",
    "\n",
    "# 3. Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(heatmap_data, cmap='YlOrRd', linewidths=.5, annot=False)\n",
    "plt.title(\"Package Scan Activity by Day and Hour\")\n",
    "plt.xlabel(\"Hour of Day (0-23)\")\n",
    "plt.ylabel(\"Day of Week\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "we notice that the busiest times for package scans are during weekdays, particularly from mid-morning to late afternoon.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets on RECPTCL_FID to analyze relationship\n",
    "merged_df = pd.merge(\n",
    "    packages_df,\n",
    "    receptacle_df,\n",
    "    on='RECPTCL_FID',\n",
    "    how='left',\n",
    "    suffixes=('_package', '_receptacle')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of packages per receptacle\n",
    "packages_per_receptacle = packages_df.groupby('RECPTCL_FID')['MAILITM_FID'].nunique()\n",
    "packages_per_receptacle.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "# Feature Extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "### stripe white spaces from IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "packages_df['RECPTCL_FID'] = packages_df['RECPTCL_FID'].str.strip()\n",
    "packages_df['MAILITM_FID'] = packages_df['MAILITM_FID'].str.strip()\n",
    "receptacle_df['RECPTCL_FID'] = receptacle_df['RECPTCL_FID'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### Check RECPTCL_FID and MAILITM_FID having same length formats\n",
    "if yes then we can split them into meaningfull parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "same=1\n",
    "print(\"\\n=== RECPTCL_FID  ===\")\n",
    "print(f\"testing if the lengths of RECPTCL_FID values are all the same:\")\n",
    "for val in packages_df['RECPTCL_FID'].values:\n",
    "    if len(str(val)) != 29 :\n",
    "        print(f\"  {val} (length: {len(str(val))})\")\n",
    "        same=0\n",
    "        break\n",
    "if same==1:\n",
    "    print('all same length' )\n",
    "\n",
    "print(\"\\n=== MAILITM_FID  ===\")\n",
    "print(f\"testing if the lengths of MAILITM_FID values are all the same:\")\n",
    "for val in packages_df['MAILITM_FID'].values:\n",
    "    if len(str(val)) != 13 :\n",
    "        print(f\"  {val} (length: {len(str(val))})\")\n",
    "        same=0\n",
    "        break\n",
    "if same==1:\n",
    "    print ('all same length' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### RECPTCL_FID Analysis\n",
    "- **Format:** 29-character string (e.g., `USORDADZALGDAUN30050001900005`)\n",
    "- **Data Quality:** No null values (1,000,000) | 215,867 unique values in receptacle dataset and 45306 unique values in packages dataset\n",
    "- **Extractable Features:**\n",
    "  - Origin Country (2 chars): US, FR, AE, etc.\n",
    "  - Destination Country (2 chars): DZ, AI, AA, etc.\n",
    "\n",
    "### MAILITM_FID Analysis\n",
    "- **Format:** 13-character string according to the S10-12 patern (e.g., `CA000132868US`, `CA000340856PK`)\n",
    "- **Data Quality:** No null values (1,000,000 packages)\n",
    "- **Extractable Features:**\n",
    "  - Service Indicator (2 chars): CA, etc.\n",
    "  - Serial Number (8 chars): 00013286, 00034085, etc.\n",
    "  - Check Digit (1 char): 8, 6, etc.\n",
    "  - Country Code (3 chars, right-stripped): US, PK.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "## Definition of the parser funtions\n",
    "These functions are responsible for spliting the IDs into parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_recptcl_fid(id_str):\n",
    "    origin_country = id_str[0:2]\n",
    "    destination_country = id_str[6:8]\n",
    "    return origin_country, destination_country\n",
    "\n",
    "def parse_mailitm_fid(id_str):\n",
    "    service_indicator = id_str[0:2]\n",
    "    serial_number = id_str[2:11]\n",
    "    country_code = id_str[11:14].strip()\n",
    "    return service_indicator, serial_number, country_code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### Apply parsing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_receptacle_df = receptacle_df.copy()\n",
    "parsed_receptacle_df[['origin_country', 'destination_country']] = parsed_receptacle_df['RECPTCL_FID'].apply(lambda x: pd.Series(parse_recptcl_fid(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_packages_df = packages_df.copy()\n",
    "parsed_packages_df[['service_indicator', 'serial_number', 'country_code']] = parsed_packages_df['MAILITM_FID'].apply(lambda x: pd.Series(parse_mailitm_fid(x)))\n",
    "parsed_packages_df[['origin_country','destination_country']] = parsed_packages_df['RECPTCL_FID'].apply(lambda x: pd.Series(parse_recptcl_fid(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "### show samples of new parsed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=== packages_df sample with new parsed columns ===\")\n",
    "parsed_packages_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== receptacle_df sample with new parsed columns ===\")\n",
    "parsed_receptacle_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "# Analysis of the extrcted features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "## 1. parsed_packages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n--- Unique Value Counts for parsed_packages_df ---\")\n",
    "print(\"\\nFor receptacle FID parsing:\")\n",
    "print(f\"Unique origin_country values: {parsed_packages_df['origin_country'].nunique()}\")\n",
    "print(f\"Unique destination_country values: {parsed_packages_df['destination_country'].nunique()}\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"\\nFor mail item FID parsing:\")\n",
    "print(f\"Unique service_indicator values: {parsed_packages_df['service_indicator'].nunique()}\")\n",
    "print(f\"Unique country_code values: {parsed_packages_df['country_code'].nunique()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "## 2. parsed_receptacle_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Unique Value Counts for parsed_receptacle_df ---\")\n",
    "print(f\"Unique origin_country values: {parsed_receptacle_df['origin_country'].nunique()}\")\n",
    "print(f\"Unique destination_country values: {parsed_receptacle_df['destination_country'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## List values of the new columns obtained from receptacle FID parsing for both parsed dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "### 1. for parsed_packages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#listing the values \n",
    "print(\"\\n--- Values of origin_country ---\")\n",
    "print(parsed_packages_df['origin_country'].unique())\n",
    "\n",
    "print(\"\\n--- Values of destination_country ---\")\n",
    "print(parsed_packages_df['destination_country'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "### 2. for parsed_receptacle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#listing the values \n",
    "print(\"\\n--- Values of origin_country ---\")\n",
    "print(parsed_receptacle_df['origin_country'].unique())\n",
    "\n",
    "print(\"\\n--- Values of destination_country ---\")\n",
    "print(parsed_receptacle_df['destination_country'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "### Do the intersection of origin_country of both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the intersection of origin_country values in both parsed datasets\n",
    "packages_origin_countries = set(parsed_packages_df['origin_country'].unique())\n",
    "receptacle_origin_countries = set(parsed_receptacle_df['origin_country'].unique())\n",
    "common_origin_countries = packages_origin_countries.intersection(receptacle_origin_countries)\n",
    "print(\"number of common origin_country values in both parsed datasets:\", len(common_origin_countries))\n",
    "print(f\"\\nCommon origin_country values in both paesed datasets: \")\n",
    "print(common_origin_countries)\n",
    "# remaining ones \n",
    "remaining_in_packages = packages_origin_countries - common_origin_countries\n",
    "remaining_in_receptacle = receptacle_origin_countries - common_origin_countries\n",
    "print(f\"Remaining origin_country values only in parsed_packages_df:\")\n",
    "print(remaining_in_packages)\n",
    "print(f\"Remaining origin_country values only in parsed_receptacle_df:\")\n",
    "print(remaining_in_receptacle )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "### list the values of both service indicators and country code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "### 1. service indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Values of service_indicator ---\")\n",
    "print(parsed_packages_df['service_indicator'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    " we can see that there are values that don't follow the standards in the S10-12 format so we need to handle that correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform country_code to uppercase for consistency\n",
    "parsed_packages_df['service_indicator'] = parsed_packages_df['service_indicator'].str.upper()\n",
    "print(\"values of service_indicator after transformation to uppercase:\")\n",
    "print(parsed_packages_df['service_indicator'].unique())\n",
    "print(\"number of unique service indicators after transformation:\", parsed_packages_df['service_indicator'].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "### 2. country code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Values of country codes ---\")\n",
    "\n",
    "print(parsed_packages_df['country_code'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "we can see that many values for the country codes are numbers instead of ISO 3166-1 format these values should be replaced by the values of origin country gotten from the receptacle when doing the preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "### replace them with the correct origin country code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for index, row in parsed_packages_df.iterrows():\n",
    "    parsed_packages_df.at[index, 'country_code'] = row['country_code'].upper()\n",
    "    if row['origin_country'] != row['country_code']:\n",
    "        count += 1\n",
    "print(f\"Number of rows where origin_country does not match country_code: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "### replace them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in parsed_packages_df.iterrows():\n",
    "    if row['origin_country'] != row['country_code']:\n",
    "        parsed_packages_df.at[index, 'country_code'] = row['origin_country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the unique values again\n",
    "print(\"\\n--- Values of country codes after correction ---\")\n",
    "print(parsed_packages_df['country_code'].unique())\n",
    "print(\"number of unique country codes after correction:\", parsed_packages_df['country_code'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "## visualization of Origin Country distribution according to number of packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "### 1. for the parsed_packages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_country_counts = parsed_packages_df['origin_country'].value_counts().head(20)\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.barh(origin_country_counts.index, origin_country_counts.values, color='steelblue')\n",
    "plt.xlabel('Count', fontsize=11)\n",
    "plt.ylabel('Origin Country', fontsize=11)\n",
    "plt.title('Top 20 Origin Countries by packages count', fontsize=12, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "### 2. for the parsed_receptacle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_country_counts = parsed_receptacle_df['origin_country'].value_counts().head(20)\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.barh(origin_country_counts.index, origin_country_counts.values, color='steelblue')\n",
    "plt.xlabel('Count', fontsize=11)\n",
    "plt.ylabel('Origin Country', fontsize=11)\n",
    "plt.title('Top 20 Origin Countries by receptacle count', fontsize=12, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "## Visualiation of the service indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_indicator_count = parsed_packages_df['service_indicator'].value_counts().head(20)\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.barh(service_indicator_count.index, service_indicator_count.values, color='mediumseagreen')\n",
    "plt.xlabel('Count', fontsize=11)\n",
    "plt.ylabel('Service Indicator', fontsize=11)\n",
    "plt.title('Top 20 Service Indicators by packages count', fontsize=12, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "# Origin–Destination Flow Analysis\n",
    "\n",
    "This section investigates the flow of receptacles and packages from origin countries to destination. We examine:\n",
    "- packages count by origin country\n",
    "- Top origin countries delivering to each destination\n",
    "- Visual representation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "### 1. parsed_packages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages count by origin country\n",
    "origin_country_volume = parsed_packages_df['origin_country'].value_counts()\n",
    "print(\"\\n--- Packages count by Origin Country ---\")\n",
    "print(origin_country_volume.head(15))\n",
    "\n",
    "# Create origin_country × destination matrix\n",
    "flow_matrix = pd.crosstab(parsed_packages_df['origin_country'], \n",
    "                           parsed_packages_df['destination_country'])\n",
    "\n",
    "# Keep only top 10 origin countries and top 10 destination countries for readability\n",
    "top_origins = parsed_packages_df['origin_country'].value_counts().head(10).index\n",
    "top_arrivals = parsed_packages_df['destination_country'].value_counts().head(10).index\n",
    "\n",
    "flow_matrix_top = flow_matrix.loc[top_origins, top_arrivals]\n",
    "\n",
    "print(\"\\n--- Origin Country × destination Country (Top 10 × Top 10) ---\")\n",
    "print(flow_matrix_top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize origin × destination country flow\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(flow_matrix_top, cmap='YlOrRd', annot=True, fmt='d', \n",
    "            cbar_kws={'label': 'packages Count'}, linewidths=0.5)\n",
    "plt.title('packages Flow: Origin Country × destination country (Top 10 × Top 10)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Arrival Hub', fontsize=12)\n",
    "plt.ylabel('Origin Country', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "### 2. parsed_receptacle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# receptacle count by origin country\n",
    "origin_country_receptacle_volume = parsed_receptacle_df['origin_country'].value_counts()\n",
    "print(\"\\n--- Receptacle count by Origin Country ---\")\n",
    "print(origin_country_receptacle_volume.head(15))\n",
    "\n",
    "destination__receptacle_volume=parsed_receptacle_df['destination_country'].value_counts()\n",
    "print(\"\\n--- Receptacle count by destination ---\")\n",
    "print(destination__receptacle_volume.head(15))\n",
    "\n",
    "# Create origin_country × destination matrix\n",
    "receptacle_flow_matrix = pd.crosstab(parsed_receptacle_df['origin_country'], \n",
    "                           parsed_receptacle_df['destination_country'])\n",
    "\n",
    "# Keep only top 10 origin countries and top 10 destination countries for readability\n",
    "receptacle_top_origins = parsed_receptacle_df['origin_country'].value_counts().head(10).index\n",
    "receptacle_top_arrivals = parsed_receptacle_df['destination_country'].value_counts().head(10).index\n",
    "\n",
    "receptacle_flow_matrix_top = receptacle_flow_matrix.loc[receptacle_top_origins, receptacle_top_arrivals]\n",
    "\n",
    "print(\"\\n--- Origin Country × destination Country (Top 10 × Top 10) ---\")\n",
    "print(receptacle_flow_matrix_top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize origin × destination country flow\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(receptacle_flow_matrix_top, cmap='YlOrRd', annot=True, fmt='d', \n",
    "            cbar_kws={'label': 'receptacles Count'}, linewidths=0.5)\n",
    "plt.title('receptacles Flow: Origin Country × destination country (Top 10 × Top 10)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Arrival Hub', fontsize=12)\n",
    "plt.ylabel('Origin Country', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {},
   "source": [
    "### create pairs (origin, destination) for more detailed analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_packages_df['origin_destination'] = parsed_packages_df['origin_country'] + '_' + parsed_packages_df['destination_country']\n",
    "parsed_receptacle_df['origin_destination'] = parsed_receptacle_df['origin_country'] + '_' + parsed_receptacle_df['destination_country']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "listing the obtained values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('(origin_destination) pairs obtained for ')\n",
    "print(\"\\nfor parsed_packages_df :\")\n",
    "print(\"\\nNumber of unique values\", parsed_packages_df['origin_destination'].nunique())\n",
    "print(\"\\nValues : \")\n",
    "print(parsed_packages_df['origin_destination'].unique())\n",
    "print(\"\\nfor parsed_receptacles_df :\")\n",
    "print(\"\\nNumber of unique values\", parsed_receptacle_df['origin_destination'].nunique())\n",
    "print(\"\\nValues : \")\n",
    "print(parsed_receptacle_df['origin_destination'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "### visualization of obtained results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "### 1. parsed_packages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_dest_counts = parsed_packages_df['origin_destination'].value_counts()\n",
    "top_origin_dest_counts= origin_dest_counts.head(15)\n",
    "plt.figure(figsize=(14, 7))\n",
    "top_origin_dest_counts.plot(kind='bar')\n",
    "plt.title('Histogram of (origin, destination) Pairs Based on Package Counts')\n",
    "plt.xlabel('Origin_Destination')\n",
    "plt.ylabel('Number of Packages')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "\n",
    "### 2. parsed_receptacle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_dest_counts = parsed_receptacle_df['origin_destination'].value_counts()\n",
    "top_origin_dest_counts = origin_dest_counts.head(15)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "top_origin_dest_counts.plot(kind='bar')\n",
    "plt.title('Histogram of (origin, destination) Pairs Based on receptacle Counts')\n",
    "plt.xlabel('Origin_Destination')\n",
    "plt.ylabel('Number of receptacles')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97",
   "metadata": {},
   "source": [
    "## origin_destination X etablissments analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "## 1. current etablissment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "### a. parsed_packages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For parsed_packages_df: visualize the histogram of counts by (origin_destination, etablissement_postal) pairs\n",
    "\n",
    "# First, select top N most common (origin_destination, etablissement_postal) pairs for clarity\n",
    "pair_counts_current = parsed_packages_df.groupby(['origin_destination', 'etablissement_postal']).size().reset_index(name='count')\n",
    "\n",
    "# Sort and keep only top N pairs (by count)\n",
    "top_n = 20\n",
    "top_pairs_current = pair_counts_current.sort_values('count', ascending=False).head(top_n)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.barplot(\n",
    "    data=top_pairs_current,\n",
    "    x='count',\n",
    "    y=top_pairs_current.apply(lambda x: f\"{x['origin_destination']} | {x['etablissement_postal']}\", axis=1),\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Top (Origin-Destination, Current Etablissement) Pairs by Package Counts')\n",
    "plt.xlabel('Number of Packages')\n",
    "plt.ylabel('(Origin_Destination | Current Etablissement)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "### b. parsed_receptacle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For parsed_receptacle_df: visualize the histogram of counts by (origin_destination, etablissement_postal) pairs\n",
    "\n",
    "# First, select top N most common (origin_destination, etablissement_postal) pairs for clarity\n",
    "pair_counts_current_receptacle = parsed_receptacle_df.groupby(['origin_destination', 'etablissement_postal']).size().reset_index(name='count')\n",
    "\n",
    "# Sort and keep only top N pairs (by count)\n",
    "top_n = 20\n",
    "top_pairs_current_receptacle = pair_counts_current_receptacle.sort_values('count', ascending=False).head(top_n)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.barplot(\n",
    "    data=top_pairs_current_receptacle,\n",
    "    x='count',\n",
    "    y=top_pairs_current_receptacle.apply(lambda x: f\"{x['origin_destination']} | {x['etablissement_postal']}\", axis=1),\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Top (Origin-Destination, Current Etablissement) Pairs by Receptacle Counts')\n",
    "plt.xlabel('Number of Receptacles')\n",
    "plt.ylabel('(Origin_Destination | Current Etablissement)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "we can see that the ETAB0002 is dominating and we remark that when the destination is DZ\n",
    "we'll try to confirm that by taking into consideration the destination only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For parsed_receptacle_df: visualize the histogram of counts by (destination_country, etablissement_postal) pairs\n",
    "\n",
    "# First, select top N most common (destination_country, etablissement_postal) pairs for clarity\n",
    "pair_counts_dest_receptacle = parsed_receptacle_df.groupby(['destination_country', 'etablissement_postal']).size().reset_index(name='count')\n",
    "\n",
    "# Sort and keep only top N pairs (by count)\n",
    "top_n = 20\n",
    "top_pairs_dest_receptacle = pair_counts_dest_receptacle.sort_values('count', ascending=False).head(top_n)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.barplot(\n",
    "    data=top_pairs_dest_receptacle,\n",
    "    x='count',\n",
    "    y=top_pairs_dest_receptacle.apply(lambda x: f\"{x['destination_country']} | {x['etablissement_postal']}\", axis=1),\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Top (Destination Country, Current Etablissement) Pairs by Receptacle Counts')\n",
    "plt.xlabel('Number of Receptacles')\n",
    "plt.ylabel('(Destination Country | Current Etablissement)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105",
   "metadata": {},
   "source": [
    "### This is to test the origin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For parsed_receptacle_df: visualize the histogram of counts by (origin_country, etablissement_postal) pairs\n",
    "\n",
    "# First, select top N most common (origin_country, etablissement_postal) pairs for clarity\n",
    "pair_counts_origin_receptacle = parsed_receptacle_df.groupby(['origin_country', 'etablissement_postal']).size().reset_index(name='count')\n",
    "\n",
    "# Sort and keep only top N pairs (by count)\n",
    "top_n = 20\n",
    "top_pairs_origin_receptacle = pair_counts_origin_receptacle.sort_values('count', ascending=False).head(top_n)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.barplot(\n",
    "    data=top_pairs_origin_receptacle,\n",
    "    x='count',\n",
    "    y=top_pairs_origin_receptacle.apply(lambda x: f\"{x['origin_country']} | {x['etablissement_postal']}\", axis=1),\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Top (Origin Country, Current Etablissement) Pairs by Receptacle Counts')\n",
    "plt.xlabel('Number of Receptacles')\n",
    "plt.ylabel('(Origin Country | Current Etablissement)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {},
   "source": [
    "most of the values with ETAB0002 values are european countries in addition to AE and China(CN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108",
   "metadata": {},
   "source": [
    "## 2. Next etablissement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109",
   "metadata": {},
   "source": [
    "### a. parsed_packages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For parsed_packages_df: visualize the histogram of counts by (origin_destination, next_etablissement_postal)\n",
    "\n",
    "# First, select top N most common (origin_destination, next_etablissement_postal) pairs for clarity\n",
    "pair_counts = parsed_packages_df.groupby(['origin_destination', 'next_etablissement_postal']).size().reset_index(name='count')\n",
    "\n",
    "# Sort and keep only top N pairs (by count)\n",
    "top_n = 20\n",
    "top_pairs = pair_counts.sort_values('count', ascending=False).head(top_n)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.barplot(\n",
    "    data=top_pairs,\n",
    "    x='count',\n",
    "    y=top_pairs.apply(lambda x: f\"{x['origin_destination']} | {x['next_etablissement_postal']}\", axis=1),\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Top (Origin-Destination, Next Etablissement) Pairs by Package Counts')\n",
    "plt.xlabel('Number of Packages')\n",
    "plt.ylabel('(Origin_Destination | Next Etablissement)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111",
   "metadata": {},
   "source": [
    "### b. parsed_receptacle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For parsed_receptacle_df: visualize the histogram of counts by (origin_destination, next_etablissement_postal)\n",
    "\n",
    "# First, select top N most common (origin_destination, next_etablissement_postal) pairs for clarity\n",
    "pair_counts_recept = parsed_receptacle_df.groupby(['origin_destination', 'next_etablissement_postal']).size().reset_index(name='count')\n",
    "\n",
    "# Sort and keep only top N pairs (by count)\n",
    "top_n = 20\n",
    "top_pairs_recept = pair_counts_recept.sort_values('count', ascending=False).head(top_n)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.barplot(\n",
    "    data=top_pairs_recept,\n",
    "    x='count',\n",
    "    y=top_pairs_recept.apply(lambda x: f\"{x['origin_destination']} | {x['next_etablissement_postal']}\", axis=1),\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Top (Origin-Destination, Next Etablissement) Pairs by Receptacle Counts')\n",
    "plt.xlabel('Number of Receptacles')\n",
    "plt.ylabel('(Origin_Destination | Next Etablissement)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113",
   "metadata": {},
   "source": [
    "Do for origin and for destination separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For parsed_receptacle_df: visualize the histogram of counts by destination_country and next_etablissement_postal\n",
    "\n",
    "# First, select top N most common (destination_country, next_etablissement_postal) pairs for clarity\n",
    "pair_counts_dest = parsed_receptacle_df.groupby(['destination_country', 'next_etablissement_postal']).size().reset_index(name='count')\n",
    "\n",
    "# Sort and keep only top N pairs (by count)\n",
    "top_n = 20\n",
    "top_pairs_dest = pair_counts_dest.sort_values('count', ascending=False).head(top_n)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.barplot(\n",
    "    data=top_pairs_dest,\n",
    "    x='count',\n",
    "    y=top_pairs_dest.apply(lambda x: f\"{x['destination_country']} | {x['next_etablissement_postal']}\", axis=1),\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Top (Destination Country, Next Etablissement) Pairs by Receptacle Counts')\n",
    "plt.xlabel('Number of Receptacles')\n",
    "plt.ylabel('(Destination_Country | Next Etablissement)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For parsed_receptacle_df: visualize the histogram of counts by origin_country and next_etablissement_postal\n",
    "\n",
    "# First, select top N most common (origin_country, next_etablissement_postal) pairs for clarity\n",
    "pair_counts_origin = parsed_receptacle_df.groupby(['origin_country', 'next_etablissement_postal']).size().reset_index(name='count')\n",
    "\n",
    "# Sort and keep only top N pairs (by count)\n",
    "top_n = 20\n",
    "top_pairs_origin = pair_counts_origin.sort_values('count', ascending=False).head(top_n)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.barplot(\n",
    "    data=top_pairs_origin,\n",
    "    x='count',\n",
    "    y=top_pairs_origin.apply(lambda x: f\"{x['origin_country']} | {x['next_etablissement_postal']}\", axis=1),\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Top (Origin Country, Next Etablissement) Pairs by Receptacle Counts')\n",
    "plt.xlabel('Number of Receptacles')\n",
    "plt.ylabel('(Origin_Country | Next Etablissement)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116",
   "metadata": {},
   "source": [
    "from the analysis we can see that there are some etablissments that get congested forming a sort of loop (ETAB0030, ETAB0002, ETAB0006)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "### Time analysis regarding origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118",
   "metadata": {},
   "source": [
    "### 1. parsed_packages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the parsed_packages_df by date and origin_country to count packages per month per origin country\n",
    "parsed_packages_df['date'] = pd.to_datetime(parsed_packages_df['date'])\n",
    "\n",
    "# Group by origin_country and resample by month\n",
    "ts_by_origin = parsed_packages_df.groupby(['origin_country', pd.Grouper(key='date', freq='ME')])['MAILITM_FID'].count().reset_index()\n",
    "\n",
    "# Choose top 5 origin countries by total count for plotting\n",
    "top_origin = parsed_packages_df['origin_country'].value_counts().head(5).index\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "for origin in top_origin:\n",
    "    ts = ts_by_origin[ts_by_origin['origin_country'] == origin]\n",
    "    plt.plot(ts['date'], ts['MAILITM_FID'], marker='o', label=origin)\n",
    "\n",
    "plt.title('Monthly Package count by Origin Country')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Packages')\n",
    "plt.legend(title='Origin Country')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120",
   "metadata": {},
   "source": [
    "### 2. parsed_receptacle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the parsed_receptacle_df by date and origin_country to count receptacles per month per origin country\n",
    "parsed_receptacle_df['date'] = pd.to_datetime(parsed_receptacle_df['date'])\n",
    "\n",
    "# Group by origin_country and resample by month\n",
    "ts_by_origin_recept = parsed_receptacle_df.groupby(['origin_country', pd.Grouper(key='date', freq='ME')])['RECPTCL_FID'].count().reset_index()\n",
    "\n",
    "# Choose top 5 origin countries by total count for plotting\n",
    "top_origin_recept = parsed_receptacle_df['origin_country'].value_counts().head(5).index\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "for origin in top_origin_recept:\n",
    "    ts = ts_by_origin_recept[ts_by_origin_recept['origin_country'] == origin]\n",
    "    plt.plot(ts['date'], ts['RECPTCL_FID'], marker='o', label=origin)\n",
    "\n",
    "plt.title('Monthly Receptacle count by Origin Country')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Receptacles')\n",
    "plt.legend(title='Origin Country')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122",
   "metadata": {},
   "source": [
    "### Time analysis by destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the parsed_packages_df by date and destination_country to count packages per month per destination country\n",
    "parsed_packages_df['date'] = pd.to_datetime(parsed_packages_df['date'])\n",
    "\n",
    "# Group by destination_country and resample by month\n",
    "ts_by_dest = parsed_packages_df.groupby(['destination_country', pd.Grouper(key='date', freq='ME')])['MAILITM_FID'].count().reset_index()\n",
    "\n",
    "# Choose top 5 destination countries by total count for plotting\n",
    "top_dest = parsed_packages_df['destination_country'].value_counts().head(5).index\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "for dest in top_dest:\n",
    "    ts = ts_by_dest[ts_by_dest['destination_country'] == dest]\n",
    "    plt.plot(ts['date'], ts['MAILITM_FID'], marker='o', label=dest)\n",
    "\n",
    "plt.title('Monthly Package count by Destination Country')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Packages')\n",
    "plt.legend(title='Destination Country')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124",
   "metadata": {},
   "source": [
    "### 2. parsed_receptacle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the parsed_receptacle_df by date and destination_country to count receptacles per month per destination country\n",
    "parsed_receptacle_df['date'] = pd.to_datetime(parsed_receptacle_df['date'])\n",
    "\n",
    "# Group by destination_country and resample by month \n",
    "ts_by_dest_recept = parsed_receptacle_df.groupby(['destination_country', pd.Grouper(key='date', freq='ME')])['RECPTCL_FID'].count().reset_index()\n",
    "\n",
    "# Choose top 5 destination countries by total count for plotting\n",
    "top_dest_recept = parsed_receptacle_df['destination_country'].value_counts().head(5).index\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "for dest in top_dest_recept:\n",
    "    ts = ts_by_dest_recept[ts_by_dest_recept['destination_country'] == dest]\n",
    "    plt.plot(ts['date'], ts['RECPTCL_FID'], marker='o', label=dest)\n",
    "\n",
    "plt.title('Monthly Receptacle count by Destination Country')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Receptacles')\n",
    "plt.legend(title='Destination Country')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126",
   "metadata": {},
   "source": [
    "## Creating additional features \n",
    " 1. 'flow_type' column with values: 'inbound' (to DZ), 'outbound' (from DZ), 'local' (DZ to DZ), otherwise 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'flow_type' column with values: 'inbound' (to DZ), 'outbound' (from DZ), 'local' (DZ to DZ), otherwise 'other'\n",
    "def determine_flow_type(row):\n",
    "    if row['destination_country'] == 'DZ' and row['origin_country'] == 'DZ':\n",
    "        return 'local'\n",
    "    elif row['destination_country'] == 'DZ':\n",
    "        return 'inbound'\n",
    "    elif row['origin_country'] == 'DZ':\n",
    "        return 'outbound'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "parsed_packages_df['flow_type'] = parsed_packages_df.apply(determine_flow_type, axis=1)\n",
    "parsed_receptacle_df['flow_type'] = parsed_receptacle_df.apply(determine_flow_type, axis=1)\n",
    "\n",
    "# Print the number of each flow_type in parsed_packages_df\n",
    "print(\"Flow type counts in parsed_packages_df:\")\n",
    "print(parsed_packages_df['flow_type'].value_counts())\n",
    "\n",
    "# Print the number of each flow_type in parsed_receptacle_df\n",
    "print(\"\\nFlow type counts in parsed_receptacle_df:\")\n",
    "print(parsed_receptacle_df['flow_type'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128",
   "metadata": {},
   "source": [
    "we can see that there are some values of flow type with the type \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 10 rows of origin_country and destination_country for flow_type 'other' in parsed_receptacle_df\n",
    "print(parsed_receptacle_df.loc[parsed_receptacle_df['flow_type'] == 'other', ['origin_country', 'destination_country']].head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130",
   "metadata": {},
   "source": [
    "## Analysis of the relation between the flow_type and the event_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131",
   "metadata": {},
   "source": [
    "## 1. parsed_packages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Analyse relation between flow_type and EVENT_TYPE_CD in parsed_packages_df\n",
    "\n",
    "plt.figure(figsize=(14,7))\n",
    "ax = sns.countplot(data=parsed_packages_df, x=\"EVENT_TYPE_CD\", hue=\"flow_type\", palette='Set2')\n",
    "plt.title(\"Distribution of EVENT_TYPE_CD by flow_type in parsed_packages_df\")\n",
    "plt.xlabel(\"EVENT_TYPE_CD\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend(title=\"Flow Type\")\n",
    "plt.tight_layout()\n",
    "for c in ax.containers:\n",
    "    ax.bar_label(c, label_type='edge', fontsize=8, padding=2)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133",
   "metadata": {},
   "source": [
    "## 2. parsed_receptacle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each flow_type, list the unique EVENT_TYPE_CD values and the most frequent EVENT_TYPE_CD value\n",
    "for flow in parsed_receptacle_df['flow_type'].unique():\n",
    "    event_types = parsed_receptacle_df.loc[parsed_receptacle_df['flow_type'] == flow, 'EVENT_TYPE_CD'].unique()\n",
    "    most_common_event_type = parsed_receptacle_df.loc[parsed_receptacle_df['flow_type'] == flow, 'EVENT_TYPE_CD'].mode()\n",
    "    print(f\"Flow type: {flow}\")\n",
    "    print(f\"EVENT_TYPE_CD values: {sorted(event_types)}\")\n",
    "    if not most_common_event_type.empty:\n",
    "        print(f\"Most frequent EVENT_TYPE_CD: {most_common_event_type.iloc[0]}\")\n",
    "    else:\n",
    "        print(\"No EVENT_TYPE_CD available\")\n",
    "    print()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "ax = sns.countplot(data=parsed_receptacle_df, x=\"EVENT_TYPE_CD\", hue=\"flow_type\", palette='Set1')\n",
    "plt.title(\"Distribution of EVENT_TYPE_CD by flow_type in parsed_receptacle_df\")\n",
    "plt.xlabel(\"EVENT_TYPE_CD\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend(title=\"Flow Type\")\n",
    "plt.tight_layout()\n",
    "\n",
    "for c in ax.containers:\n",
    "    ax.bar_label(c, label_type='edge', fontsize=8, padding=2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136",
   "metadata": {},
   "source": [
    "we can see that there are major event types related to the inbound flow type( coming to DZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137",
   "metadata": {},
   "source": [
    "# Track multiple receptacles just to see the flow of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track multiple receptacles: visualize all events for 5 different RECPTCL_FID in parsed_receptacle_df\n",
    "# Pick 5 unique RECPTCL_FID values to demonstrate\n",
    "num_examples = 5\n",
    "example_receptacle_ids = parsed_receptacle_df['RECPTCL_FID'].drop_duplicates().iloc[:num_examples]\n",
    "for rid in example_receptacle_ids:\n",
    "    print(\"\\n--- Events for RECPTCL_FID:\", rid, \"---\")\n",
    "    display(parsed_receptacle_df[parsed_receptacle_df['RECPTCL_FID'] == rid][['RECPTCL_FID', 'date', 'EVENT_TYPE_CD', 'etablissement_postal', 'next_etablissement_postal']].sort_values('date').reset_index(drop=True))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "for i, receptacle_id in enumerate(example_receptacle_ids):\n",
    "    ex_df = parsed_receptacle_df[parsed_receptacle_df['RECPTCL_FID'] == receptacle_id].sort_values('date')\n",
    "    plt.plot(\n",
    "        ex_df['date'],\n",
    "        ex_df['EVENT_TYPE_CD'],\n",
    "        marker='o',\n",
    "        label=f\"RECPTCL_FID: {receptacle_id}\"\n",
    "    )\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(f\"Event Timeline (EVENT_TYPE_CD) for {num_examples} Receptacles\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"EVENT_TYPE_CD\")\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139",
   "metadata": {},
   "source": [
    "# calculating the time of existence for each receptacle/ package \n",
    "   ## processing_duration \n",
    "   Note : this duration is calculated between min and make date and doesn't give the exact duration since it is not suming the duration between each event\n",
    "   further analysis could be conducted to take that ninto consideration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140",
   "metadata": {},
   "source": [
    "### 1. parsed_packages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate processing_duration (time from first to last event per MAILITM_FID)\n",
    "# For each mail item, sort events by date, get min and max date per mail item\n",
    "pkg_duration_df = (\n",
    "    parsed_packages_df\n",
    "    .sort_values(['MAILITM_FID', 'date'])\n",
    "    .groupby('MAILITM_FID')['date']\n",
    "    .agg(['min', 'max'])\n",
    "    .reset_index()\n",
    ")\n",
    "pkg_duration_df.columns = ['MAILITM_FID', 'min_date', 'max_date']\n",
    "pkg_duration_df['processing_duration'] = pkg_duration_df['max_date'] - pkg_duration_df['min_date']\n",
    "\n",
    "# Merge 'processing_duration' back to parsed_packages_df\n",
    "parsed_packages_df = parsed_packages_df.merge(\n",
    "    pkg_duration_df[['MAILITM_FID', 'processing_duration']],\n",
    "    on='MAILITM_FID',\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142",
   "metadata": {},
   "source": [
    "display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display processing_duration statistics\n",
    "print(parsed_packages_df[['MAILITM_FID', 'date', 'processing_duration']].drop_duplicates(subset=['processing_duration']).head(10))\n",
    "#print the max value of processing_duration\n",
    "max_duration = parsed_packages_df['processing_duration'].max()\n",
    "#print the mail item(s) with the max processing_duration\n",
    "max_duration_items = parsed_packages_df[parsed_packages_df['processing_duration'] == max_duration]['MAILITM_FID'].unique()\n",
    "print(f\"\\nMaximum processing duration: {max_duration}\")\n",
    "print(f\"Mail item(s) with maximum processing duration: {max_duration_items}\")\n",
    "\n",
    "#print the min value of processing_duration\n",
    "min_duration = parsed_packages_df['processing_duration'].min()\n",
    "#print the mail item(s) with the min processing_duration\n",
    "min_duration_items = parsed_packages_df[parsed_packages_df['processing_duration'] == min_duration]['MAILITM_FID'].unique()\n",
    "print(f\"\\nMinimum processing duration: {min_duration}\")\n",
    "print(f\"Mail item(s) with minimum processing duration: {min_duration_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144",
   "metadata": {},
   "source": [
    "visualization of the distribution of the packages according to the processing duration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of packages by processing_duration\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Convert processing_duration to total days for better visualization\n",
    "parsed_packages_df['processing_duration_days'] = parsed_packages_df['processing_duration'].dt.total_seconds() / (24 * 3600)\n",
    "\n",
    "# Create histogram\n",
    "plt.hist(parsed_packages_df['processing_duration_days'], bins=100, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Processing Duration (days)', fontsize=11)\n",
    "plt.ylabel('Number of Packages', fontsize=11)\n",
    "plt.title('Distribution of Packages by Processing Duration', fontsize=12, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Processing Duration Statistics:\")\n",
    "print(f\"Mean: {parsed_packages_df['processing_duration_days'].mean():.2f} days\")\n",
    "print(f\"Median: {parsed_packages_df['processing_duration_days'].median():.2f} days\")\n",
    "print(f\"Std Dev: {parsed_packages_df['processing_duration_days'].std():.2f} days\")\n",
    "print(f\"Min: {parsed_packages_df['processing_duration_days'].min():.2f} days\")\n",
    "print(f\"Max: {parsed_packages_df['processing_duration_days'].max():.2f} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146",
   "metadata": {},
   "source": [
    "- This doesn't give a lot of insights, we try to analyse the event type and the duration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for processing_duration by EVENT_TYPE_CD\n",
    "duration_by_event = (\n",
    "    parsed_packages_df\n",
    "    .groupby(\"EVENT_TYPE_CD\")['processing_duration_days']\n",
    "    .describe()\n",
    ")\n",
    "print(\"Processing Duration Statistics by EVENT_TYPE_CD:\")\n",
    "print(duration_by_event)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Visualize boxplot of processing_duration by EVENT_TYPE_CD\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(x='EVENT_TYPE_CD', y='processing_duration_days', data=parsed_packages_df, showfliers=False)\n",
    "plt.title('Processing Duration by EVENT_TYPE_CD', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('EVENT_TYPE_CD', fontsize=12)\n",
    "plt.ylabel('Processing Duration (days)', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148",
   "metadata": {},
   "source": [
    "- Bar chart showing mean processing_duration by EVENT_TYPE_CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_duration_by_event = parsed_packages_df.groupby('EVENT_TYPE_CD')['processing_duration_days'].mean().sort_values(ascending=False)\n",
    "plt.figure(figsize=(14, 7))\n",
    "mean_duration_by_event.plot(kind='barh', color='steelblue')\n",
    "plt.xlabel('Mean Processing Duration (days)', fontsize=11)\n",
    "plt.ylabel('EVENT_TYPE_CD', fontsize=11)\n",
    "plt.title('Mean Processing Duration by EVENT_TYPE_CD', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150",
   "metadata": {},
   "source": [
    "now we can see that some events type is a kind of groups of similar event types that have approximatly the same average number of processing duration "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151",
   "metadata": {},
   "source": [
    "## 2. parsed_receptacle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate processing_duration (time from first to last event per RECPTCL_FID)\n",
    "# For each receptacle, sort events by date, get min and max date per receptacle\n",
    "rec_duration_df = (\n",
    "    parsed_receptacle_df\n",
    "    .sort_values(['RECPTCL_FID', 'date'])\n",
    "    .groupby('RECPTCL_FID')['date']\n",
    "    .agg(['min', 'max'])\n",
    "    .reset_index()\n",
    ")\n",
    "rec_duration_df['processing_duration'] = rec_duration_df['max'] - rec_duration_df['min']\n",
    "\n",
    "# Merge 'processing_duration' back to parsed_receptacle_df\n",
    "parsed_receptacle_df = parsed_receptacle_df.merge(\n",
    "    rec_duration_df[['RECPTCL_FID', 'processing_duration']],\n",
    "    on='RECPTCL_FID',\n",
    "    how='left'\n",
    ")\n",
    "# Display the first few rows to show the obtained processing_duration values\n",
    "print(parsed_receptacle_df[['RECPTCL_FID', 'date', 'processing_duration']].head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153",
   "metadata": {},
   "source": [
    "### Analysis of the relation between the processing duration and the event type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of processing_duration by EVENT_TYPE_CD\n",
    "parsed_receptacle_df['processing_duration_hours'] = parsed_receptacle_df['processing_duration'].dt.total_seconds() / 3600\n",
    "# Summary statistics for processing_duration by EVENT_TYPE_CD\n",
    "duration_by_event = (\n",
    "    parsed_receptacle_df\n",
    "    .groupby(\"EVENT_TYPE_CD\")['processing_duration_hours']\n",
    "    .describe()\n",
    ")\n",
    "print(\"Processing Duration Statistics by EVENT_TYPE_CD:\")\n",
    "print(duration_by_event)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# Visualize boxplot of processing_duration by EVENT_TYPE_CD\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(x='EVENT_TYPE_CD', y='processing_duration_hours', data=parsed_receptacle_df, showfliers=False)\n",
    "plt.title('Processing Duration by EVENT_TYPE_CD', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('EVENT_TYPE_CD', fontsize=12)\n",
    "plt.ylabel('Processing Duration (hours)', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155",
   "metadata": {},
   "source": [
    "-  Bar chart showing mean processing_duration by EVENT_TYPE_CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_duration_by_event = parsed_receptacle_df.groupby('EVENT_TYPE_CD')['processing_duration_hours'].mean().sort_values(ascending=False)\n",
    "plt.figure(figsize=(14, 7))\n",
    "mean_duration_by_event.plot(kind='barh', color='steelblue')\n",
    "plt.xlabel('Mean Processing Duration (hours)', fontsize=11)\n",
    "plt.ylabel('EVENT_TYPE_CD', fontsize=11)\n",
    "plt.title('Mean Processing Duration by EVENT_TYPE_CD', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157",
   "metadata": {},
   "source": [
    "-  Heatmap: EVENT_TYPE_CD vs Flow Type with mean duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pivot_table = parsed_receptacle_df.pivot_table(\n",
    "    values='processing_duration_hours',\n",
    "    index='EVENT_TYPE_CD',\n",
    "    columns='flow_type',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pivot_table, annot=True, fmt='.1f', cmap='RdYlGn_r', cbar_kws={'label': 'Mean Duration (hours)'})\n",
    "plt.title('Mean Processing Duration: EVENT_TYPE_CD vs Flow Type', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Flow Type', fontsize=12)\n",
    "plt.ylabel('EVENT_TYPE_CD', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159",
   "metadata": {},
   "source": [
    "- Correlation: Count events per receptacle and duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_count_per_receptacle = parsed_receptacle_df.groupby('RECPTCL_FID').size().reset_index(name='event_count')\n",
    "receptacle_duration = parsed_receptacle_df[['RECPTCL_FID', 'processing_duration_hours']].drop_duplicates()\n",
    "event_duration_corr = event_count_per_receptacle.merge(receptacle_duration, on='RECPTCL_FID')\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.scatter(event_duration_corr['event_count'], event_duration_corr['processing_duration_hours'], alpha=0.5, s=30)\n",
    "plt.xlabel('Number of Events per Receptacle', fontsize=11)\n",
    "plt.ylabel('Processing Duration (hours)', fontsize=11)\n",
    "plt.title('Relationship between Event Count and Processing Duration', fontsize=12, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation coefficient\n",
    "correlation = event_duration_corr['event_count'].corr(event_duration_corr['processing_duration_hours'])\n",
    "print(f\"\\nCorrelation between event count and processing duration: {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161",
   "metadata": {},
   "source": [
    "we can see that having more events reduces the duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162",
   "metadata": {},
   "source": [
    "### Analysis of the relation between the processing_duration and flow_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll analyze the relationship between processing_duration and flow_type .\n",
    "\n",
    "duration_by_flow = (\n",
    "    parsed_receptacle_df\n",
    "    .groupby(\"flow_type\")['processing_duration']\n",
    "    .describe()\n",
    ")\n",
    "print(duration_by_flow)\n",
    "\n",
    "# Visualize the distribution: boxplot of processing_duration by flow_type\n",
    "\n",
    "# Convert processing_duration to total hours for visualization\n",
    "#parsed_receptacle_df['processing_duration_hours'] = parsed_receptacle_df['processing_duration'].dt.total_seconds() / 3600\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x='flow_type', y='processing_duration_hours', data=parsed_receptacle_df, showfliers=False)\n",
    "\n",
    "plt.title('Processing Duration by Flow Type')\n",
    "plt.xlabel('Flow Type')\n",
    "plt.ylabel('Processing Duration (hours)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164",
   "metadata": {},
   "source": [
    "From this boxplot of Processing Duration by Flow Type, we can extract several clear results and insights:\n",
    "\n",
    "1. Inbound flow\n",
    "\n",
    "Highest processing times overall\n",
    "\n",
    "Median is relatively high (around ~110–120 hours)\n",
    "\n",
    "Very wide spread (high variability) → large IQR and long whiskers\n",
    "\n",
    "Extreme delays exist (outliers reaching ~450+ hours)\n",
    "\n",
    "2. Outbound flow\n",
    "\n",
    "Moderate processing time\n",
    "\n",
    "Median lower than inbound (~80–90 hours)\n",
    "\n",
    "Still variable, but less extreme than inbound\n",
    "\n",
    "Some long delays, but fewer and smaller than inbound\n",
    "\n",
    "\n",
    "3. Local flow\n",
    "\n",
    "Very low processing duration\n",
    "\n",
    "Tight distribution (low variance)\n",
    "\n",
    "Almost no outliers\n",
    "\n",
    "Local receptacles are processed quickly and consistently.\n",
    "\n",
    "4. Other flow\n",
    "\n",
    "Near-zero processing duration\n",
    "\n",
    "Almost no variability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165",
   "metadata": {},
   "source": [
    "### Show the row with the max value of processing_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_row = rec_duration_df.loc[rec_duration_df['processing_duration'].idxmax()]\n",
    "print(max_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = parsed_receptacle_df.loc[parsed_receptacle_df['RECPTCL_FID'] == 'FRCDGADZALGAAEN99999999990102', ['RECPTCL_FID', 'date']]\n",
    "print(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168",
   "metadata": {},
   "source": [
    "this is probably an error in the typing since they are the only values existing of the receptacle and the three are from march the diff is in the year of the third"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f297f3cb4997ab",
   "metadata": {},
   "source": [
    "# extracting more features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910200f7cdc2bff1",
   "metadata": {},
   "source": [
    "## receptacle dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58608fd1b6600530",
   "metadata": {},
   "source": [
    "intuitively we think that the number of etablissement crossed by the receptacle can affect the processing duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a47eb7a48a451",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the number of unique etablissement crossed by each receptacle\n",
    "etab_counts = (\n",
    "    parsed_receptacle_df\n",
    "    .groupby('RECPTCL_FID')['etablissement_postal']\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .rename(columns={'etablissement_postal': 'num_etablissements'})\n",
    ")\n",
    "# Merge back to parsed_receptacle_df\n",
    "parsed_receptacle_df = parsed_receptacle_df.merge(\n",
    "    etab_counts,\n",
    "    on='RECPTCL_FID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "parsed_receptacle_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390350a9a38a4e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the correlation between num_etablissements and processing_duration\n",
    "correlation = parsed_receptacle_df[['num_etablissements', 'processing_duration_hours']].corr().iloc[0,1]\n",
    "print(f\"Correlation between number of etablissments and processing duration (hours): {correlation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebe5920e9bc6bee",
   "metadata": {},
   "source": [
    "considering the size of the dataset this correlation is not bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39346975b6a548c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship between num_etablissements and processing_duration\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.lineplot(\n",
    "    data=parsed_receptacle_df,\n",
    "    x='num_etablissements',\n",
    "    y='processing_duration_hours',\n",
    "    marker='o'\n",
    ")\n",
    "plt.title('Processing Duration vs. Number of Etablissements Crossed')\n",
    "plt.xlabel('Number of Etablissements Crossed')\n",
    "plt.ylabel('Processing Duration (hours)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4218cafe4f760f",
   "metadata": {},
   "source": [
    "the line plot shows a clear increasing trend indicating that as the number of etablissments crossed increases the processing duration also increases, but the correlation value shows that the relation is weak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f70b32b6e9d2642",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='num_etablissements', y='processing_duration_hours', data=parsed_receptacle_df, showfliers=False)\n",
    "plt.xlabel(\"Number of Etablissements Crossed\")\n",
    "plt.ylabel(\"Processing Duration (hours)\")\n",
    "plt.title(\"Boxplot showing the variation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8299d83d3c9f2fcc",
   "metadata": {},
   "source": [
    "by looking at the boxplot we can see that the median processing duration increases with the number of etablissments crossed but the variance also increases significantly,this explains the weak correlation value obtained earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e305ad3d7cd8",
   "metadata": {},
   "source": [
    "## packages dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f48edf38072b02",
   "metadata": {},
   "source": [
    "we test the same hypothesis for the packages dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4512745c2ac638bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the number of unique etablissement crossed by each package\n",
    "etab_counts_pkg = (\n",
    "    parsed_packages_df\n",
    "    .groupby('MAILITM_FID')['etablissement_postal']\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .rename(columns={'etablissement_postal': 'num_etablissements'})\n",
    ")\n",
    "# Merge back to parsed_packages_df\n",
    "parsed_packages_df = parsed_packages_df.merge(\n",
    "    etab_counts_pkg,\n",
    "    on='MAILITM_FID',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b747887ade7361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the correlation between num_etablissements and processing_duration\n",
    "correlation_pkg = parsed_packages_df[['num_etablissements', 'processing_duration_days']].corr().iloc[0,1]\n",
    "print(f\"Correlation between number of etablissments and processing duration (days): {correlation_pkg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b386e7428afda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship between num_etablissements and processing_duration\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.lineplot(\n",
    "    data=parsed_packages_df,\n",
    "    x='num_etablissements',\n",
    "    y='processing_duration_days',\n",
    "    marker='o'\n",
    ")\n",
    "plt.title('Processing Duration vs. Number of Etablissements Crossed')\n",
    "plt.xlabel('Number of Etablissements Crossed')\n",
    "plt.ylabel('Processing Duration (days)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c8ed10e8f1b9f2",
   "metadata": {},
   "source": [
    "the correlation is weaker than that of the receptacle dataset this is probably because of variation in packages types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9544f3c053ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of processing_duration by num_etablissements\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='num_etablissements', y='processing_duration_days', data=parsed_packages_df, showfliers=False)\n",
    "plt.xlabel(\"Number of Etablissements Crossed\")\n",
    "plt.ylabel(\"Processing Duration (days)\")\n",
    "plt.title(\"Boxplot showing the variation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405797cedb01e7b3",
   "metadata": {},
   "source": [
    "relation starts to appear more when the number of etablissments crossed is more than 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d352c891",
   "metadata": {},
   "source": [
    "## Data Splitting to training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4491b9b",
   "metadata": {},
   "source": [
    "- We propose to split datasets (which are already sorted by date) using `TimeSeriesSplit` from `sklearn.model_selection`\n",
    "- because we need to keep all rows for a specific `MAILITM_FID` as a single block and not separated.\n",
    "- older rows are kept for the `training_set` and newer ones are kept for the `testing_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13048e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "packages_cat_features = [col for col in parsed_packages_df.column if col.dtype in ['object']]\n",
    "receptacles_cat_features = [col for col in parsed_receptacle_df.column if col.dtype in ['object']]\n",
    "\n",
    "packages_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), packages_cat_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "receptacles_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), receptacles_cat_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "packages_tscv = TimeSeriesSplit()\n",
    "receptacles_tscv = TimeSeriesSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_packages_splits(preprocessor, df):\n",
    "    splits = []\n",
    "    df = df.sort_values(['MAILITM_FID', 'date'])\n",
    "    for train_idx, test_idx in packages_tscv.split(df):\n",
    "        X_train = preprocessor.fit_transform(df.iloc[train_idx])\n",
    "        X_test  = preprocessor.transform(df.iloc[test_idx])\n",
    "        splits.append((X_train, X_test))\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dfbf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_splits = build_splits(packages_preprocessor, parsed_packages_df)\n",
    "receptacles_splits = build_splits(receptacles_preprocessor, parsed_receptacle_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6556fc",
   "metadata": {},
   "source": [
    "**We still need to deal with the high dimensionality we get from `OneHotEncoder`**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
