{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Load Merged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used clean one\n",
    "merged_df = pd.read_csv( '../data/interim/interim_merged_packages_receptacle_df.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Sort Data Chronologically\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sort chronologically\n",
    "merged_df = merged_df.sort_values('date_package').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "\n",
    "### Remove unnecessary index columns that were created during the merge operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop(columns=[\n",
    "    'Unnamed: 0_package',\n",
    "    'Unnamed: 0_receptacle',\n",
    "    #'RECPTCL_FID', 'MAILITM_FID', 'serial_number'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Convert the date column to datetime format and extract temporal features:\n",
    "- **hour**: Hour of day when package was processed\n",
    "- **day_of_week**: Day of the week (Sunday -->Thursday)\n",
    "- **is_weekend**: Binary flag indicating weekend (Friday/Saturday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['date_package'] = pd.to_datetime(merged_df['date_package'])\n",
    "\n",
    "merged_df['hour'] = merged_df['date_package'].dt.hour\n",
    "merged_df['day_of_week'] = merged_df['date_package'].dt.dayofweek\n",
    "merged_df['is_weekend'] = merged_df['day_of_week'].isin([4, 5]).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "\n",
    "### Create a binary feature indicating whether a package exceeded the 15-day processing threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['delay_flag'] = (merged_df['processing_duration_days'] > 15).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "\n",
    "### Calculate the standardized delay score (z-score) for processing duration within each origin-destination pair. This normalizes delays relative to typical processing times for each route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['delay_zscore'] = (\n",
    "    merged_df\n",
    "    .groupby('origin_destination_package')['processing_duration_days']\n",
    "    .transform(lambda x: (x - x.mean()) / (x.std() + 1e-6))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "\n",
    "### Normalize the processing delay by the number of establishments the package passed through. This accounts for packages that take longer routes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['delay_per_etab'] = (\n",
    "    merged_df['processing_duration_days'] /\n",
    "    (merged_df['num_etablissements_package'] + 1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "\n",
    "### Create a route identifier by combining the current and next etablissment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['pkg_route_step'] = (\n",
    "    merged_df['etablissement_postal_package'] + '→' + merged_df['next_etablissement_postal_package']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "\n",
    "### Calculate how common each package route is in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_route_freq = merged_df['pkg_route_step'].value_counts(normalize=True)\n",
    "merged_df['pkg_route_freq'] = merged_df['pkg_route_step'].map(pkg_route_freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "\n",
    "### Calculate how frequently each postal establishment appears as the current or next location in the routing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "etab_freq = pd.concat([\n",
    "    merged_df['etablissement_postal_package'],\n",
    "    merged_df['next_etablissement_postal_package']\n",
    "]).value_counts()\n",
    "\n",
    "merged_df['current_etab_freq'] = merged_df['etablissement_postal_package'].map(etab_freq)\n",
    "merged_df['next_etab_freq'] = merged_df['next_etablissement_postal_package'].map(etab_freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Package-Level Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_features = [\n",
    "    'processing_duration_days',\n",
    "    'delay_flag',\n",
    "    'delay_per_etab',\n",
    "    'delay_zscore',\n",
    "    'num_etablissements_package',\n",
    "    'pkg_route_freq',\n",
    "    'current_etab_freq',\n",
    "    'next_etab_freq',\n",
    "    'hour',\n",
    "    'is_weekend'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Receptacle Level\n",
    "\n",
    "### receptacle route identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['rec_route_step'] = (\n",
    "    merged_df['etablissement_postal_receptacle'] + '→' + merged_df['next_etablissement_postal_receptacle']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Aggregate package-level statistics at the receptacle level to create features such as:\n",
    "- Number of packages in receptacle\n",
    "- Average and standard deviation of processing duration\n",
    "- Average delay metrics\n",
    "- Average package route rarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "receptacle_route_stats = (\n",
    "    merged_df\n",
    "    .groupby('RECPTCL_FID')\n",
    "    .agg(\n",
    "        rec_route=('rec_route_step', 'first'),\n",
    "        num_packages=('MAILITM_FID', 'count'),\n",
    "        avg_processing_days=('processing_duration_days', 'mean'),\n",
    "        std_processing_days=('processing_duration_days', 'std'),\n",
    "        avg_delay_per_etab=('delay_per_etab', 'mean'),\n",
    "        avg_pkg_route_rarity=('pkg_route_freq', 'mean')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Fill NaNs\n",
    "receptacle_route_stats['std_processing_days'] = receptacle_route_stats['std_processing_days'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Receptacle Route Frequency\n",
    "\n",
    "Calculate how common each receptacle route is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_route_freq = receptacle_route_stats['rec_route'].value_counts(normalize=True)\n",
    "receptacle_route_stats['rec_route_freq'] = receptacle_route_stats['rec_route'].map(rec_route_freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Receptacle Flow Type Frequency\n",
    "\n",
    "Map flow type frequencies to each receptacle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_flow_type = merged_df.groupby('RECPTCL_FID')['flow_type_receptacle'].first().reset_index()\n",
    "\n",
    "flow_type_freq = rec_flow_type['flow_type_receptacle'].value_counts(normalize=True)\n",
    "rec_flow_type['flow_type_freq'] = rec_flow_type['flow_type_receptacle'].map(flow_type_freq)\n",
    "\n",
    "receptacle_route_stats = receptacle_route_stats.merge(\n",
    "    rec_flow_type[['RECPTCL_FID', 'flow_type_freq']],\n",
    "    on='RECPTCL_FID',\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Receptacle Level Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_features = [\n",
    "    'num_packages',\n",
    "    'avg_processing_days',\n",
    "    'std_processing_days',\n",
    "    'avg_delay_per_etab',\n",
    "    'avg_pkg_route_rarity',\n",
    "    'rec_route_freq',\n",
    "    'flow_type_freq'\n",
    "]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
